{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/stab/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "RDKit WARNING: [14:53:03] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/home/pocha/projects')\n",
    "from metstab_pred.src.utils import get_configs_and_model\n",
    "from metstab_pred.src.config import utils_section, csv_section\n",
    "# from metstab_pred.src.data import unlog_stability\n",
    "\n",
    "from metstab_pred.src.shap_analysis.utils import load_shap_files, load_ml_files, Task, Category\n",
    "# from metstab_pred.src.shap_analysis.preprocessing import get_smiles_true_predicted, get_smiles_correct\n",
    "# from metstab_pred.src.shap_analysis.preprocessing import get_smiles_stability_value, get_smiles_train_test\n",
    "from metstab_pred.src.shap_analysis.preprocessing import get_present_features, filter_samples\n",
    "# from metstab_pred.src.shap_analysis.preprocessing import e, enough\n",
    "from metstab_pred.src.shap_analysis.analyses import situation_at_threshold\n",
    "\n",
    "from metstab_pred.src.shap_analysis.test_separation_point import find_optimal_separation_point as kfind, SeparationType\n",
    "from metstab_pred.src.shap_analysis.categorisation import well_separated\n",
    "from metstab_pred.src.shap_analysis.well_separated import purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/pocha/dane_phd/random_split/'\n",
    "    \n",
    "exp = 'h-kr-c-nb'\n",
    "exp = 'r-ma-r-svm'\n",
    "some_model = osp.join(directory, 'ml', exp)\n",
    "some_shaps = osp.join(directory, 'shap', exp)\n",
    "\n",
    "# data preparation\n",
    "data_cfg, repr_cfg, task_cfg, model_cfg, model_pickle = get_configs_and_model(some_model)\n",
    "x_train, x_test, smiles_train, smiles_test = load_ml_files(some_model)\n",
    "task = Task(task_cfg[utils_section]['task'])\n",
    "shap_cfg, smiles_order, X_full, morgan_repr, true_ys, preds, classes_order, expected_values, shap_values, background_data = load_shap_files(some_shaps, task)\n",
    "X_full_df = pd.DataFrame(X_full, columns=list(range(X_full.shape[1])), index=smiles_order)\n",
    "\n",
    "# filter samples\n",
    "my_feats = get_present_features(x_train, 0.01)\n",
    "to_analyse_X, to_analyse_df, to_analyse_shaps, smi_order, mol_indices, feature_order = filter_samples(smiles_order, my_feats, X_full, shap_values, task, smiles_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_full, shap_values, feature_order, task):\n",
    "    \n",
    "    for f in feature_order:\n",
    "        feat_idx = feature_order.index(f)  # indeks cechy o nazwie \"f\"\n",
    "        \n",
    "        if task == Task.REGRESSION:\n",
    "            separation_result = [well_separated(X_full[:,feat_idx], shap_values[:,feat_idx], task, n_way=2), ]\n",
    "            classes = [None, ]\n",
    "        elif task == Task.CLASSIFICATION:\n",
    "            separation_result = well_separated(X_full[:,feat_idx], shap_values[:,:,feat_idx], task, n_way=2)\n",
    "            classes = list(range(len(separation_result)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task: {task}. Known tasks are `regression` and `classification`.\")\n",
    "\n",
    "        reference_result = []\n",
    "        for c in classes:\n",
    "            ref = kfind(shap_values, X_full, feature_order, f, task, class_index=c, extras=True)\n",
    "            reference_result.append(ref)\n",
    "            \n",
    "        for my, ref, c in zip(separation_result, reference_result, classes):\n",
    "            # checking score\n",
    "            my_score = set([my.score])\n",
    "            ref_score = set([kk.score/len(X_full) for kk in ref])\n",
    "            assert my_score == ref_score, f\"{my_score} != {ref_score}\"\n",
    "            \n",
    "            # checking thresholds and their corresponding group tagging\n",
    "            my_tre_val = dict(zip(my.thresholds, my.values))\n",
    "            ref_tr_val = dict([(kk.x, (0,1) if kk.type == SeparationType.ZEROES_ON_LEFT else (1,0)) for kk in ref])\n",
    "            assert my_tre_val == ref_tr_val, f\"{my_tre_val} != {ref_tr_val}\"\n",
    "\n",
    "            # checking purities\n",
    "            for my_t, (my_lp, my_rp) in zip(my.thresholds, my.purities):\n",
    "                l0, l1, r0, r1 = situation_at_threshold(my_t, f, to_analyse_shaps, to_analyse_X, feature_order, task, class_index=c, print_func=None)\n",
    "\n",
    "                mines = (my_lp, my_rp)\n",
    "                reference = (purity(l0, l1), purity(r0, r1))\n",
    "                assert np.all(np.isclose(mines, reference, equal_nan=True)), f\"{mines} != {reference}\"\n",
    "                \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "test(to_analyse_X, to_analyse_shaps, feature_order, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "## Task.REGRESSION\n",
    "for f in feature_order:\n",
    "    # separation_result\n",
    "    my = well_separated(X_full[:,f], shap_values[:,f], task, n_way=2)\n",
    "    k = kfind(to_analyse_shaps, to_analyse_X, feature_order, f, task, class_index=None, extras=True)\n",
    "    \n",
    "    #for (my, k) in zip(separation_result, k_result):\n",
    "        \n",
    "    my_score = set([my.score])\n",
    "    k_score = set([kk.score/len(X_full) for kk in k])\n",
    "    assert my_score == k_score, f\"{my_score} != {k_score}\"\n",
    "\n",
    "    my_tre_val = dict(zip(my.thresholds, my.values))\n",
    "    k_tr_val = dict([(kk.x, (0,1) if kk.type == SeparationType.ZEROES_ON_LEFT else (1,0)) for kk in k])\n",
    "    assert my_tre_val == k_tr_val, f\"{my_tre_val} != {k_tr_val}\"\n",
    "\n",
    "    for my_t, (my_lp, my_rp) in zip(my.thresholds, my.purities):\n",
    "        l0, l1, r0, r1 = situation_at_threshold(my_t, f, to_analyse_shaps, to_analyse_X, feature_order, task, class_index=None, print_func=None)\n",
    "\n",
    "        mines = (my_lp, my_rp)\n",
    "        reference = (purity(l0, l1), purity(r0, r1))\n",
    "        assert np.all(np.isclose(mines, reference, equal_nan=True)), f\"{mines} != {reference}\"\n",
    "        \n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Task.CLASSIFICATION\n",
    "for f in feature_order:\n",
    "    separation_result = well_separated(X_full[:,f], shap_values[:,:,f], task, n_way=2)\n",
    "    \n",
    "    k_result = []\n",
    "    for c in [0, 1, 2]:\n",
    "        kres = kfind(to_analyse_shaps, to_analyse_X, feature_order, f, task, c, extras=True)\n",
    "        k_result.append(kres)\n",
    "    \n",
    "    for c, (my, k) in enumerate(zip(separation_result, k_result)):\n",
    "        \n",
    "        my_score = set([my.score])\n",
    "        k_score = set([kk.score/len(X_full) for kk in k])\n",
    "        assert my_score == k_score, f\"{my_score} != {k_score}\"\n",
    "        \n",
    "        my_tre_val = dict(zip(my.thresholds, my.values))\n",
    "        k_tr_val = dict([(kk.x, (0,1) if kk.type == SeparationType.ZEROES_ON_LEFT else (1,0)) for kk in k])\n",
    "        assert my_tre_val == k_tr_val, f\"{my_tre_val} != {k_tr_val}\"\n",
    "        \n",
    "        for my_t, (my_lp, my_rp) in zip(my.thresholds, my.purities):\n",
    "            l0, l1, r0, r1 = situation_at_threshold(my_t, f, to_analyse_shaps, to_analyse_X, feature_order, task, class_index=c, print_func=None)\n",
    "            \n",
    "            mines = (my_lp, my_rp)\n",
    "            reference = (purity(l0, l1), purity(r0, r1))\n",
    "            assert np.all(np.isclose(mines, reference, equal_nan=True)), f\"{mines} != {reference}\"\n",
    "        \n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_find_separation_point_well_separated(shap_values, X_full, feature_order, task, class_idx):\n",
    "    \n",
    "    \n",
    "#     for i in feature_order:\n",
    "#         SeparationResult = namedtuple('SeparationResult', ['score', 'thresholds', 'values', 'purities'])\n",
    "        \n",
    "#         separation_result = well_separated(feature_values, shap_values, task, n_way=2)\n",
    "#         kmax_correct, kpurity, kbest_thresholds = kfind(shap_values, X_full, feature_order, i, task, class_idx)\n",
    "\n",
    "#         assert max_correct == kmax_correct, AssertionError(f'{max_correct} != {kmax_correct}')\n",
    "\n",
    "#         best_thresholds = np.array(sorted(best_thresholds))\n",
    "#         kbest_thresholds = np.array(sorted(kbest_thresholds))\n",
    "#         assert len(best_thresholds) == len(kbest_thresholds), AssertionError(f'{best_thresholds} != {kbest_thresholds}')\n",
    "#         assert set(best_thresholds) == set(kbest_thresholds), AssertionError(f'{best_thresholds} != {kbest_thresholds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stab] *",
   "language": "python",
   "name": "conda-env-stab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
